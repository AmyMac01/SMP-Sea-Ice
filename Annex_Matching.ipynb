{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMP and snow pit profile matching\n",
    "An example of SMP profiles at snow pit locations are scaled to account for differences\n",
    "in the target snowpack structure. Because the SMP and density cutter profiles are physically\n",
    "displaced we use a brute-force approach to match them as best as possible using a 4 step\n",
    "procedure\n",
    "\n",
    "1. Make a first guess at the density from the SMP using the P15\n",
    "2. Break up the SMP profile into L_RESAMPLE sized layers\n",
    "3. Randomly scale each layer according to MAX_STRETCH_LAYER\n",
    "4. Compare against density profile\n",
    "5. Select best fit scaling where RMSE and R are optimized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community packages\n",
    "import os \n",
    "import numpy as np\n",
    "np.random.seed(2019) \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Local packages\n",
    "import smpfunc #SMP helper functions\n",
    "\n",
    "# Import SLF SMP Package\n",
    "from snowmicropyn import Profile, proksch2015, loewe2012\n",
    "\n",
    "# Import data\n",
    "pit_summary = pd.read_csv(\"./data/Pit/pit_summary.csv\")\n",
    "pit_desnity = pd.read_csv(\"./data/Pit/pit_density.csv\")\n",
    "input_data = os.path.abspath(\"./data/SMP/Calibration\")\n",
    "\n",
    "# Set constants\n",
    "CUTTER_SIZE = 15 # Half the height of the density cutter in mm\n",
    "WINDOW_SIZE = 5 # SMP analysis window in mm\n",
    "H_RESAMPLE = 1 # delta height in mm for standardized SMP profiles\n",
    "L_RESAMPLE = 50 # layer unit height in mm for SMP matching\n",
    "MAX_STRETCH_LAYER = 0.75 # Max layer change in % of height\n",
    "MAX_STRETCH_OVERALL = 0.15 # Max profile change in % of total height\n",
    "NUM_TESTS = 10000\n",
    "\n",
    "#coeffs = pickle.load(open('./output/density_kfolds_coeffs.sav', 'rb'))\n",
    "\n",
    "axis_value_size = 12\n",
    "axis_label_size = 14\n",
    "\n",
    "coeffs = pickle.load(open('./output/density_k19b_coeffs.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SMP calibration profiles, should be 25 for the ECCC case\n",
    "def load_smp(smp_file):\n",
    "    p = Profile.load(smp_file)\n",
    "    p = smpfunc.preprocess(p, smoothing = 0)\n",
    "    ground  = p.detect_ground()\n",
    "    surface  = p.detect_surface()\n",
    "    return p\n",
    "\n",
    "file_list = []\n",
    "for file in os.listdir(input_data):\n",
    "    if file.endswith(\".pnt\"):\n",
    "        file_list.append(os.path.join(input_data, file))\n",
    "        \n",
    "smp_data = [load_smp(file) for file in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp = smp_data[11]\n",
    "smp_file_num = int(smp.name[-4:])\n",
    "pit_df  = pit_summary[pit_summary['SMPF'] == smp_file_num] # Select the matching pit\n",
    "density_df = pit_desnity[pit_desnity['ID'] == pit_df['ID'].values[0]]\n",
    "density_df = density_df.assign(relative_height=np.abs(((density_df['TOP']*10) - CUTTER_SIZE) - density_df['TOP'].max()*10).values)\n",
    "# Make first guess at microstructure based on original profile\n",
    "l2012 = loewe2012.calc(smp.samples_within_snowpack(), window=WINDOW_SIZE)\n",
    "p2015 = proksch2015.calc(smp.samples_within_snowpack(), window=WINDOW_SIZE)\n",
    "\n",
    "# Estimate offset of the snow depth and SMP profile\n",
    "smp_profile_height = p2015.distance.max()\n",
    "smp_height_diff = pit_df.MPD.values*1000 - smp_profile_height\n",
    "\n",
    "# Create new SMP resampled arrays and determine the number of layers\n",
    "depth_array = np.arange(0, p2015.distance.max() + smp_height_diff, H_RESAMPLE)\n",
    "density_array = np.interp(depth_array,p2015.distance,p2015.P2015_density)\n",
    "force_array = np.interp(depth_array,p2015.distance,l2012.force_median)\n",
    "l_array = np.interp(depth_array,p2015.distance,l2012.L2012_L)\n",
    "\n",
    "smp_df = pd.DataFrame({'distance': depth_array, \n",
    "                       'density': density_array,\n",
    "                       'force_median': force_array,\n",
    "                       'l': l_array})\n",
    "\n",
    "num_sections = np.ceil(len(smp_df.index)/L_RESAMPLE).astype(int)\n",
    "random_tests = [smpfunc.random_stretch(x, MAX_STRETCH_OVERALL, MAX_STRETCH_LAYER) for x in np.repeat(num_sections, NUM_TESTS)] \n",
    "\n",
    "scaled_profiles = [smpfunc.scale_profile(test, smp_df.distance.values, smp_df.density.values, L_RESAMPLE, H_RESAMPLE) for test in random_tests]\n",
    "compare_profiles = [smpfunc.extract_samples(dist, rho, density_df.relative_height.values, CUTTER_SIZE) for dist, rho in scaled_profiles]\n",
    "compare_profiles = [pd.concat([profile, density_df.reset_index()], axis=1, sort=False) for profile in compare_profiles]\n",
    "retrieved_skill = [smpfunc.calc_skill(profile, CUTTER_SIZE) for profile in compare_profiles]\n",
    "retrieved_skill = pd.DataFrame(retrieved_skill,columns = ['r','rmse','rmse_corr','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_scaling_idx = retrieved_skill.sort_values(['r', 'rmse_corr'], ascending=[False, True]).head(1).index.values\n",
    "min_scaling_coeff = random_tests[int(min_scaling_idx)]\n",
    "\n",
    "dist, scaled_l =  smpfunc.scale_profile(min_scaling_coeff, smp_df.distance.values, smp_df.l.values, L_RESAMPLE, H_RESAMPLE)\n",
    "dist, scaled_force_median = smpfunc.scale_profile(min_scaling_coeff, smp_df.distance.values, smp_df.force_median.values, L_RESAMPLE, H_RESAMPLE)\n",
    "\n",
    "result = compare_profiles[int(min_scaling_idx)].assign(l=smpfunc.extract_samples(dist, scaled_l, density_df.relative_height.values, CUTTER_SIZE).mean_samp,\n",
    "                                          force_median=smpfunc.extract_samples(dist, scaled_force_median, density_df.relative_height.values, CUTTER_SIZE).mean_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_thickness_scaled = L_RESAMPLE + (min_scaling_coeff * L_RESAMPLE)\n",
    "layer_height_scalled = layer_thickness_scaled.cumsum()\n",
    "\n",
    "layer_thickness = np.repeat(L_RESAMPLE, num_sections)\n",
    "layer_height = layer_thickness.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change in thickness\n",
    "print((depth_array.max() - layer_thickness_scaled.sum())/depth_array.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_k2019 = coeffs[0] + coeffs[1] * np.log(scaled_force_median) \\\n",
    "          + coeffs[2] * np.log(scaled_force_median) * scaled_l \\\n",
    "          + coeffs[3] * scaled_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 3 with caption\n",
    "![png](./output/figures/Fig03_matching_lowres.png)\n",
    "#### Example of the SMP processing workflow to align first guess estimates of œÅ_smp (Black lines) and snow pit measurements  (Red lines). Profiles are divided in arbitrary layers of 5 cm and randomly scaled in thickness. A best fit candidate is selected where RMSE between the snow density estimates and observations are minimized. The matching process is used to account for differences in the target snowpack between the two methods. The example shown is for Eureka site 5 on MYI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['text.usetex'] = False  # not really needed\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(10,8))\n",
    "ax1.tick_params(axis='both', which='major', labelsize=axis_value_size)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=axis_value_size)\n",
    "\n",
    "xmax = 500\n",
    "xmin = 100\n",
    "\n",
    "for l in layer_height:\n",
    "    ax1.axhline(y=l, color = 'k', alpha = 0.5, ls = 'dashed')\n",
    "\n",
    "ax1.step(result.RHO, result.relative_height-15, color = 'r')\n",
    "ax2.step(result.RHO, result.relative_height-15, color = 'r')\n",
    "ax3.step(result.RHO, result.relative_height-15, color = 'r', \n",
    "         label =  r'$\\rho_{\\mathrm{pit}}$')\n",
    "\n",
    "ax1.plot(density_array, depth_array, color = 'k')\n",
    "\n",
    "for l in layer_height_scalled:\n",
    "    ax2.axhline(y=l, color = 'k', alpha = 0.5, ls = 'dashed')\n",
    "    ax3.axhline(y=l, color = 'k', alpha = 0.5, ls = 'dashed')\n",
    "\n",
    "\n",
    "    \n",
    "ax2.plot(scaled_profiles[int(min_scaling_idx)][1],\n",
    "         scaled_profiles[int(min_scaling_idx)][0], color = 'k')\n",
    "\n",
    "\n",
    "for i in np.arange(0, len(layer_height)-1):\n",
    "    xy = (xmin, layer_height_scalled[i])\n",
    "    xy1 = (xmax,layer_height[i])\n",
    "    con = ConnectionPatch(xyA=xy, xyB=xy1, coordsA=\"data\", coordsB=\"data\",\n",
    "                       axesA=ax2, axesB=ax1, color=\"k\", alpha = 0.5, ls = 'dashed')\n",
    "    ax2.add_artist(con)\n",
    "    \n",
    "ax3.plot(density_k2019 ,scaled_profiles[int(min_scaling_idx)][0], \n",
    "         color = 'k', label = r'$\\rho_{\\mathrm{smp}}$')\n",
    "\n",
    "ax1.set_ylim(0,600)\n",
    "\n",
    "\n",
    "ax1.set_xlim(xmin,xmax)\n",
    "ax2.set_xlim(xmin,xmax)\n",
    "ax3.set_xlim(xmin,xmax)\n",
    "\n",
    "ax3.axhline(y=l, color = 'k', alpha = 0.5, ls = 'dashed', label = 'Layer')\n",
    "\n",
    "\n",
    "ax1.set_ylabel('Depth below air-snow IF [mm]', fontsize=axis_label_size)\n",
    "\n",
    "ax2.set_xlabel('Snow density [kg m$\\mathregular{^{-3}}$]', fontsize=axis_label_size)\n",
    "\n",
    "ax1.set_title('a) First guess')\n",
    "ax2.set_title('b) Layer scaled')\n",
    "ax3.set_title('c) Calibrated')\n",
    "\n",
    "ax1.invert_yaxis()\n",
    "ax2.invert_yaxis()\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "ax3.legend(fontsize=12, facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('./output/figures/Fig03_matching_lowres.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation after alignment\n",
    "np.corrcoef(result.RHO, result.mean_samp)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE after alignment\n",
    "np.sqrt(np.mean(result.RHO-result.mean_samp)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
